{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from lib.models.Res_UNet_v2 import Res_UNet_v2\n",
    "import lib.utils as utils\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "TESLA_K40c = '/gpu:1'\n",
    "GTX_1080 = '/gpu:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set experiment ID\n",
    "EXP_ID = \"Res_UNet_v2_TESTE_PLC_20_40\"\n",
    "utils.create_experiment_folders(EXP_ID)\n",
    "utils.load_experiment_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_u_net_v2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 128, 128, 32)      448       \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 64, 64, 32)        9376      \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 64, 64, 64)        18752     \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 32, 32, 64)        37184     \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 32, 32, 128)       74368     \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 16, 16, 128)       148096    \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 16, 16, 256)       296192    \n",
      "_________________________________________________________________\n",
      "sequential_7 (Sequential)    (None, 8, 8, 256)         591104    \n",
      "_________________________________________________________________\n",
      "sequential_8 (Sequential)    (None, 8, 8, 512)         1182208   \n",
      "_________________________________________________________________\n",
      "sequential_9 (Sequential)    (None, 4, 4, 512)         2361856   \n",
      "_________________________________________________________________\n",
      "sequential_10 (Sequential)   (None, 4, 4, 1024)        4723712   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  4719104   \n",
      "_________________________________________________________________\n",
      "sequential_11 (Sequential)   (None, 8, 8, 512)         4721152   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr multiple                  1179904   \n",
      "_________________________________________________________________\n",
      "sequential_12 (Sequential)   (None, 16, 16, 256)       1180928   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr multiple                  295040    \n",
      "_________________________________________________________________\n",
      "sequential_13 (Sequential)   (None, 32, 32, 128)       295552    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr multiple                  73792     \n",
      "_________________________________________________________________\n",
      "sequential_14 (Sequential)   (None, 64, 64, 64)        74048     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr multiple                  18464     \n",
      "_________________________________________________________________\n",
      "sequential_15 (Sequential)   (None, 128, 128, 32)      18592     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           multiple                  289       \n",
      "=================================================================\n",
      "Total params: 22,020,161\n",
      "Trainable params: 22,012,161\n",
      "Non-trainable params: 8,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with tf.device(GTX_1080):\n",
    "    model = Res_UNet_v2()\n",
    "    model.build((None,128,128,1))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (371026, 128, 128, 1) samples\n"
     ]
    }
   ],
   "source": [
    "train_x = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/Normalized/X_train_PLC_20_40.npy\", mmap_mode='c') \n",
    "train_y = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/Normalized/y_train.npy\", mmap_mode='c') \n",
    "\n",
    "qtd_traning = train_x.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (92800, 128, 128, 1) samples\n"
     ]
    }
   ],
   "source": [
    "valid_x_1 = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/Normalized/X_val_PLC_20_40.npy\", mmap_mode='c') \n",
    "valid_y_1 = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/Normalized/y_val.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = valid_x_1.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Normalization and Batches split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.          -0.         127.97928619 127.98652649]\n",
      "train_batches: 6397 valid_batches: 1600\n"
     ]
    }
   ],
   "source": [
    "value = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/scale_and_shift.npy\", mmap_mode='c') \n",
    "print(value)\n",
    "SHIFT_VALUE_X, SHIFT_VALUE_Y, SCALE_VALUE_X, SCALE_VALUE_Y = value[0], value[1], value[2], value[3]\n",
    "# SHIFT_VALUE_X, SHIFT_VALUE_Y, SCALE_VALUE_X, SCALE_VALUE_Y = utils.get_shift_scale_maxmin(train_x, train_y, valid_x_1, valid_y_1)\n",
    "\n",
    "mini_batch_size = 58\n",
    "num_train_minibatches = math.floor(train_x.shape[0]/mini_batch_size)\n",
    "num_val_minibatches = math.floor(valid_x_1.shape[0]/mini_batch_size)\n",
    "\n",
    "print(\"train_batches:\", num_train_minibatches, \"valid_batches:\", num_val_minibatches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default tf.keras metrics\n",
    "with tf.device(GTX_1080):\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Loss and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(GTX_1080):\n",
    "    loss_object = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    #get last saved epoch index and best result in validation step\n",
    "    CURRENT_EPOCH, BEST_VALIDATION = utils.get_model_last_data()\n",
    "    if CURRENT_EPOCH > 0:\n",
    "        print(\"Loading last model state in epoch\", CURRENT_EPOCH)\n",
    "        model.load_weights(utils.get_exp_folder_last_epoch())\n",
    "        print(\"Best validation result was PSNR=\", BEST_VALIDATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2360/6397 [10:31<17:49,  3.78it/s]"
     ]
    }
   ],
   "source": [
    "with tf.device(GTX_1080):\n",
    "    @tf.function\n",
    "    def train_step(patch_x, patch_y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(patch_x)\n",
    "            loss = loss_object(patch_y, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        train_loss(loss)\n",
    "\n",
    "    def valid_step(valid_x, valid_y, num_val_minibatches, mini_batch_size):\n",
    "        valid_mse = tf.keras.metrics.MeanSquaredError(name='train_mse')\n",
    "        valid_custom_metrics = utils.CustomMetric()\n",
    "        for i in tqdm(range(num_val_minibatches)):\n",
    "            data_x = valid_x[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "            data_y = valid_y[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "\n",
    "            data_x = tf.convert_to_tensor(data_x, dtype=tf.float32)\n",
    "            data_y = tf.convert_to_tensor(data_y, dtype=tf.float32)\n",
    "\n",
    "#             data_x = ((data_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "#             data_y = ((data_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "\n",
    "            predictions = model(data_x)\n",
    "            valid_mse(data_y, predictions)\n",
    "\n",
    "            predictions = predictions.numpy()\n",
    "            data_y = data_y.numpy()\n",
    "\n",
    "            #feed the metric evaluator\n",
    "            valid_custom_metrics.feed(data_y, predictions)\n",
    "\n",
    "        #get metric results\n",
    "        psnr, nrmse = valid_custom_metrics.result()\n",
    "        valid_mse_result = valid_mse.result().numpy()\n",
    "        valid_custom_metrics.reset_states()\n",
    "        valid_mse.reset_states()\n",
    "        return psnr, nrmse, valid_mse_result\n",
    "\n",
    "    MAX_EPOCHS = 100\n",
    "    EVAL_STEP = 1\n",
    "    CONST_GAMA = 0.001\n",
    "\n",
    "\n",
    "    for epoch in range(CURRENT_EPOCH, MAX_EPOCHS):\n",
    "\n",
    "        #TRAINING\n",
    "        print(\"TRAINING EPOCH\", epoch)\n",
    "\n",
    "        for k in tqdm(range(0, num_train_minibatches)):\n",
    "            seismic_x = train_x[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "            seismic_y = train_y[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "\n",
    "            seismic_x = tf.convert_to_tensor(seismic_x, dtype=tf.float32)\n",
    "            seismic_y = tf.convert_to_tensor(seismic_y, dtype=tf.float32)\n",
    "\n",
    "#             seismic_x = ((seismic_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "#             seismic_y = ((seismic_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "\n",
    "            train_step(seismic_x, seismic_y)\n",
    "\n",
    "        #VALIDATION\n",
    "        if epoch%EVAL_STEP == 0:\n",
    "            clear_output()\n",
    "\n",
    "            print(\"VALIDATION EPOCH\", epoch)\n",
    "            #saving last epoch model\n",
    "            model.save_weights(utils.get_exp_folder_last_epoch(), save_format='tf')\n",
    "\n",
    "            #valid with set 1\n",
    "            print(\"Validation set\")\n",
    "            psnr_1, nrmse_1, mse_1 = valid_step(valid_x_1, valid_y_1, num_val_minibatches, mini_batch_size)\n",
    "\n",
    "            #valid with set 2\n",
    "            #print(\"Validation set 2\")\n",
    "            #psnr_2, nrmse_2, mse_2 = valid_step(valid_x_2, valid_y_2, num_val_minibatches, mini_batch_size)\n",
    "            psnr_2, nrmse_2, mse_2 = 0, 0, 0\n",
    "\n",
    "            #valid with set 3\n",
    "            #print(\"Validation set 3\")\n",
    "            #psnr_3, nrmse_3, mse_3 = valid_step(valid_x_3, valid_y_3, num_val_minibatches, mini_batch_size)\n",
    "            psnr_3, nrmse_3, mse_3 = 0, 0, 0\n",
    "\n",
    "            utils.update_chart_data(epoch=epoch, train_mse=train_loss.result().numpy(), \n",
    "                                    valid_mse=[mse_1,mse_2,mse_3], psnr=[psnr_1,psnr_2,psnr_3], nrmse=[nrmse_1,nrmse_2, nrmse_3])\n",
    "            utils.draw_chart()\n",
    "\n",
    "            #saving best validation model\n",
    "            if psnr_1 > BEST_VALIDATION:\n",
    "                BEST_VALIDATION = psnr_1\n",
    "                model.save_weights(utils.get_exp_folder_best_valid(), save_format='tf')\n",
    "\n",
    "        train_loss.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.draw_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimentos results\n",
    "print(utils.get_experiment_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "model.load_weights(utils.get_exp_folder_best_valid())\n",
    "CONST_GAMA = 0.001\n",
    "\n",
    "# valid_x_1 = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_val.npy\", mmap_mode='c') \n",
    "# valid_y_1 = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_val.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = valid_x_1.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n",
    "\n",
    "# #normalization\n",
    "# test_x = utils.shift_and_normalize(test_x, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "# test_y = utils.shift_and_normalize(test_y, SHIFT_VALUE_Y, SCALE_VALUE_Y) \n",
    "\n",
    "#batches\n",
    "num_val_minibatches = math.floor(valid_x_1.shape[0]/mini_batch_size)\n",
    "# test_batches = utils.random_mini_batches(test_x, test_y, None, None, 8, seed=0)\n",
    "\n",
    "#metrics\n",
    "val_mse = tf.keras.metrics.MeanSquaredError(name='val_mse')\n",
    "val_custom_metrics = utils.CustomMetric()\n",
    "\n",
    "f = open('/home/arthursrr/Documentos/Audio_Inpainting/Datasets/idx_genders_val.json', \"r\") \n",
    "idx_gen = json.loads(f.read()) \n",
    "\n",
    "for k in idx_gen:\n",
    "    for i in tqdm(idx_gen[k]):\n",
    "        data_x = valid_x_1[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "        data_y = valid_y_1[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "\n",
    "        data_x = tf.convert_to_tensor(data_x, dtype=tf.float32)\n",
    "        data_y = tf.convert_to_tensor(data_y, dtype=tf.float32)\n",
    "\n",
    "        data_x = ((data_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "        data_y = ((data_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "\n",
    "        predictions = model(data_x)\n",
    "        test_mse(data_y, predictions)\n",
    "\n",
    "        predictions = predictions.numpy()\n",
    "        data_y = data_y.numpy()\n",
    "\n",
    "        #feed the metric evaluator\n",
    "        val_custom_metrics.feed(data_y, predictions)\n",
    "\n",
    "    #get metric results\n",
    "    psnr, nrmse = val_custom_metrics.result()\n",
    "    val_mse_result = test_mse.result().numpy()\n",
    "    val_custom_metrics.reset_states()\n",
    "    val_mse.reset_states()\n",
    "    \n",
    "    print(k ,\"\\nPSNR:\", psnr,\"\\nNRMSE:\", nrmse)\n",
    "\n",
    "# Closing file \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "model.load_weights(utils.get_exp_folder_best_valid())\n",
    "CONST_GAMA = 0.001\n",
    "test_x = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_test.npy\", mmap_mode='c') \n",
    "test_y = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_test.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = test_x.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n",
    "\n",
    "# #normalization\n",
    "# test_x = utils.shift_and_normalize(test_x, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "# test_y = utils.shift_and_normalize(test_y, SHIFT_VALUE_Y, SCALE_VALUE_Y) \n",
    "\n",
    "#batches\n",
    "num_test_minibatches = math.floor(test_x.shape[0]/mini_batch_size)\n",
    "# test_batches = utils.random_mini_batches(test_x, test_y, None, None, 8, seed=0)\n",
    "\n",
    "#metrics\n",
    "test_mse = tf.keras.metrics.MeanSquaredError(name='train_mse')\n",
    "test_custom_metrics = utils.CustomMetric()\n",
    "\n",
    "f = open('/home/arthursrr/Documentos/Audio_Inpainting/Datasets/idx_genders_test.json', \"r\") \n",
    "idx_gen = json.loads(f.read()) \n",
    "\n",
    "for k in idx_gen:\n",
    "    for i in tqdm(idx_gen[k]):\n",
    "        data_x = test_x[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "        data_y = test_y[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "\n",
    "        data_x = tf.convert_to_tensor(data_x, dtype=tf.float32)\n",
    "        data_y = tf.convert_to_tensor(data_y, dtype=tf.float32)\n",
    "\n",
    "        data_x = ((data_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "        data_y = ((data_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "\n",
    "        predictions = model(data_x)\n",
    "        test_mse(data_y, predictions)\n",
    "\n",
    "        predictions = predictions.numpy()\n",
    "        data_y = data_y.numpy()\n",
    "\n",
    "        #feed the metric evaluator\n",
    "        test_custom_metrics.feed(data_y, predictions)\n",
    "\n",
    "    #get metric results\n",
    "    psnr, nrmse = test_custom_metrics.result()\n",
    "    test_mse_result = test_mse.result().numpy()\n",
    "    test_custom_metrics.reset_states()\n",
    "    test_mse.reset_states()\n",
    "    \n",
    "    print(k ,\"\\nPSNR:\", psnr,\"\\nNRMSE:\", nrmse)\n",
    "\n",
    "# Closing file \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load best model\n",
    "model.load_weights(utils.get_exp_folder_best_valid())\n",
    "CONST_GAMA = 0.001\n",
    "test_x = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_test.npy\", mmap_mode='c') \n",
    "test_y = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_test.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = test_x.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n",
    "\n",
    "# #normalization\n",
    "# test_x = utils.shift_and_normalize(test_x, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "# test_y = utils.shift_and_normalize(test_y, SHIFT_VALUE_Y, SCALE_VALUE_Y) \n",
    "\n",
    "#batches\n",
    "num_test_minibatches = math.floor(test_x.shape[0]/mini_batch_size)\n",
    "# test_batches = utils.random_mini_batches(test_x, test_y, None, None, 8, seed=0)\n",
    "\n",
    "#metrics\n",
    "test_mse = tf.keras.metrics.MeanSquaredError(name='test_mse')\n",
    "test_custom_metrics = utils.CustomMetric()\n",
    "\n",
    "f = open('/home/arthursrr/Documentos/Audio_Inpainting/Datasets/idx_genders_test.json', \"r\") \n",
    "idx_gen = json.loads(f.read()) \n",
    "\n",
    "for k in idx_gen:\n",
    "    if k == \"Experimental\" or k == \"Hip-Hop\" or k == \"Jazz\":\n",
    "        for i in tqdm(idx_gen[k]):\n",
    "            data_x = test_x[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "            data_y = test_y[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "\n",
    "            data_x = tf.convert_to_tensor(data_x, dtype=tf.float32)\n",
    "            data_y = tf.convert_to_tensor(data_y, dtype=tf.float32)\n",
    "\n",
    "            data_x = ((data_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "            data_y = ((data_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "\n",
    "            data_x = data_x.numpy()\n",
    "            data_y = data_y.numpy()\n",
    "\n",
    "            #feed the metric evaluator\n",
    "            test_custom_metrics.feed(data_y, data_x)\n",
    "\n",
    "        #get metric results\n",
    "        psnr, nrmse = test_custom_metrics.result()\n",
    "        test_mse_result = test_mse.result().numpy()\n",
    "        test_custom_metrics.reset_states()\n",
    "        test_mse.reset_states()\n",
    "    \n",
    "        print(k ,\"\\nPSNR:\", psnr,\"\\nNRMSE:\", nrmse)\n",
    "\n",
    "# Closing file \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def griffin_lim(S, frame_length=256, fft_length=255, stride=64):\n",
    "    '''\n",
    "    TensorFlow implementation of Griffin-Lim\n",
    "    Based on https://github.com/Kyubyong/tensorflow-exercises/blob/master/Audio_Processing.ipynb\n",
    "    '''\n",
    "    S = tf.expand_dims(S, 0)\n",
    "    S_complex = tf.identity(tf.cast(S, dtype=tf.complex64))\n",
    "    y = tf.signal.inverse_stft(S_complex, frame_length, stride, fft_length=fft_length)\n",
    "    for i in range(100):\n",
    "        est = tf.signal.stft(y, frame_length, stride, fft_length=fft_length)\n",
    "        angles = est / tf.cast(tf.maximum(1e-16, tf.abs(est)), tf.complex64)\n",
    "        y = tf.signal.inverse_stft(S_complex * angles, frame_length, stride, fft_length=fft_length)\n",
    "    return tf.squeeze(y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(utils.get_exp_folder_best_valid())\n",
    "\n",
    "test_x = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_test.npy\", mmap_mode='c') \n",
    "test_y = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_test.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = test_x.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n",
    "\n",
    "#batches\n",
    "num_test_minibatches = math.floor(test_x.shape[0]/mini_batch_size)\n",
    "\n",
    "#metrics\n",
    "test_mse = tf.keras.metrics.MeanSquaredError(name='test_mse')\n",
    "test_custom_metrics = utils.CustomMetric()\n",
    "\n",
    "CONST_GAMA = 0.001\n",
    "\n",
    "f = open('/home/arthursrr/Documentos/Audio_Inpainting/Datasets/idx_genders_test.json', \"r\") \n",
    "idx_gen = json.loads(f.read()) \n",
    "\n",
    "wave_original = None\n",
    "wave_corte = None\n",
    "wave_pred = None\n",
    "\n",
    "for k in idx_gen:\n",
    "    path_gen = \"/mnt/backup/arthur/Free_Music_Archive/Teste/\"+k\n",
    "    if not os.path.exists(path_gen):\n",
    "            os.makedirs(path_gen)\n",
    "            os.makedirs(path_gen+\"/original\")\n",
    "            os.makedirs(path_gen+\"/cortado\")\n",
    "            os.makedirs(path_gen+\"/predito\")\n",
    "    for i in tqdm(idx_gen[k]):\n",
    "        data_x = test_x[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "        data_y = test_y[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "\n",
    "        data_norm = ((tf.convert_to_tensor(data_x, dtype=tf.float32)+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "\n",
    "        predictions = model(data_norm)\n",
    "        \n",
    "        predictions = (((predictions-CONST_GAMA)*SCALE_VALUE_X)-SHIFT_VALUE_X).numpy()\n",
    "        \n",
    "        #predictions = utils.inv_shift_and_normalize(predictions, SHIFT_VALUE_Y, SCALE_VALUE_Y)   \n",
    "        \n",
    "        audio_original = None\n",
    "        audio_corte = None\n",
    "        audio_pred = None\n",
    "        \n",
    "        for j in range(mini_batch_size):\n",
    "            if j==0:\n",
    "                audio_original = data_y[j,:,:,0]\n",
    "                audio_corte = data_x[j,:,:,0]\n",
    "                audio_pred = predictions[j,:,:,0]\n",
    "            else:\n",
    "                audio_original = np.concatenate((audio_original, data_y[j,:,:,0]), axis=0)\n",
    "                audio_corte = np.concatenate((audio_corte, data_x[j,:,:,0]), axis=0)\n",
    "                audio_pred = np.concatenate((audio_pred, predictions[j,:,:,0]), axis=0)\n",
    "        \n",
    "        wave_original = griffin_lim(audio_original, frame_length=256, fft_length=255, stride=64)\n",
    "        wave_corte = griffin_lim(audio_corte, frame_length=256, fft_length=255, stride=64)\n",
    "        wave_pred = griffin_lim(audio_pred, frame_length=256, fft_length=255, stride=64)\n",
    "        \n",
    "        sf.write(path_gen+\"/original/\"+str(i)+\".wav\", wave_original, 16000, subtype='PCM_16')\n",
    "        sf.write(path_gen+\"/cortado/\"+str(i)+\".wav\", wave_corte, 16000, subtype='PCM_16')\n",
    "        sf.write(path_gen+\"/predito/\"+str(i)+\".wav\", wave_pred, 16000, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pred = None\n",
    "for i in range(0, 58):\n",
    "    if i==0:\n",
    "        audio_pred = predictions[i,:,:,0]\n",
    "    else:\n",
    "        audio_pred = np.concatenate((audio_pred, predictions[i,:,:,0]), axis=0)\n",
    "audio_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_corte = None\n",
    "for i in range(0, 58):\n",
    "    if i==0:\n",
    "        audio_corte = data_x[i,:,:,0]\n",
    "    else:\n",
    "        audio_corte = np.concatenate((audio_corte, data_x[i,:,:,0]), axis=0)\n",
    "audio_corte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_original = None\n",
    "for i in range(0, 58):\n",
    "    if i==0:\n",
    "        audio_original = data_y[i,:,:,0]\n",
    "    else:\n",
    "        audio_original = np.concatenate((audio_original, data_y[i,:,:,0]), axis=0)\n",
    "audio_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_original = griffin_lim(audio_original, frame_length=256, fft_length=255, stride=64)\n",
    "ipd.Audio(wave_original, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_corte = griffin_lim(audio_corte, frame_length=256, fft_length=255, stride=64)\n",
    "ipd.Audio(wave_corte, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_pred = griffin_lim(audio_pred, frame_length=256, fft_length=255, stride=64)\n",
    "ipd.Audio(wave_pred, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import soundfile as sf\n",
    "# sf.write('x.wav', wave_corte, 16000, subtype='PCM_16')\n",
    "# sf.write('pred.wav', wave_pred, 16000, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
