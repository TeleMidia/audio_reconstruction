{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from PIL import Image\n",
    "import soundfile as sf\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import lib.utils as utils\n",
    "\n",
    "import IPython.display as ipd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set experiment ID\n",
    "EXP_ID = \"VAE\"\n",
    "utils.create_experiment_folders(EXP_ID)\n",
    "utils.load_experiment_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def sampling(args):\n",
    "        mu, sigma = args\n",
    "        std = tf.exp(0.5 * sigma)\n",
    "        eps = tf.random.normal(shape=tf.shape(std))\n",
    "        return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2dBatchLayer(filters, kernel_size, strides_=1, name_=\"\"):\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
    "    result = tf.keras.Sequential(name=name_)\n",
    "    result.add(layers.Conv2D(filters, kernel_size, strides=1, padding='same', kernel_initializer=initializer))\n",
    "    result.add(layers.BatchNormalization())\n",
    "    result.add(layers.ReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 200\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(128, 128, 1))\n",
    "\n",
    "conv1 = Conv2dBatchLayer(32, 3, name_=\"conv1\")(encoder_inputs)\n",
    "down1 = layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same')(conv1)\n",
    "\n",
    "conv2 = Conv2dBatchLayer(64, 3, name_=\"conv2\")(down1)\n",
    "down2 = layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same')(conv2)\n",
    "\n",
    "conv3 = Conv2dBatchLayer(128, 3, name_=\"conv3\")(down2)\n",
    "down3 = layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same')(conv3)\n",
    "\n",
    "conv4 = Conv2dBatchLayer(256, 3, name_=\"conv4\")(down3)\n",
    "down4 = layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same')(conv4)\n",
    "\n",
    "conv5 = Conv2dBatchLayer(512, 3, name_=\"conv5\")(down4)\n",
    "down5 = layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same')(conv5)\n",
    "\n",
    "conv6 = Conv2dBatchLayer(1024, 3, name_=\"conv6\")(down5)\n",
    "\n",
    "\n",
    "x = layers.Flatten(name=\"flatten\")(conv6)\n",
    "x = layers.Dense(200, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "# z = Sampling()([z_mean, z_log_var])\n",
    "z = layers.Lambda(sampling, name='sampling_latent')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
    "\n",
    "x = layers.Dense(4 * 4 * 1024, activation=\"relu\")(z)\n",
    "x = layers.Reshape((4, 4, 1024))(x)\n",
    "\n",
    "up5 = layers.Conv2DTranspose(512, 3, activation='relu', strides=2, padding='same', kernel_initializer=initializer, name=\"up5\")(conv6)\n",
    "concat5 = layers.Concatenate(name=\"concat5\")([conv5, up5])\n",
    "conv7 = Conv2dBatchLayer(512, 3, name_=\"conv7\")(concat5)\n",
    "\n",
    "up4 = layers.Conv2DTranspose(256, 3, activation='relu', strides=2, padding='same', kernel_initializer=initializer, name=\"up4\")(conv7)\n",
    "concat4 = layers.Concatenate(name=\"concat4\")([conv4, up4])\n",
    "conv8 = Conv2dBatchLayer(256, 3, name_=\"conv8\")(concat4)\n",
    "\n",
    "up3 = layers.Conv2DTranspose(128, 3, activation='relu', strides=2, padding='same', kernel_initializer=initializer, name=\"up3\")(conv8)\n",
    "concat3 = layers.Concatenate(name=\"concat3\")([conv3, up3])\n",
    "conv9 = Conv2dBatchLayer(128, 3, name_=\"conv9\")(concat3)\n",
    "\n",
    "up2 = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same', kernel_initializer=initializer, name=\"up2\")(conv9)\n",
    "concat2 = layers.Concatenate(name=\"concat2\")([conv2, up2])\n",
    "conv10 = Conv2dBatchLayer(64, 3, name_=\"conv10\")(concat2)\n",
    "\n",
    "up1 = layers.Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same', kernel_initializer=initializer, name=\"up1\")(conv10)\n",
    "concat1 = layers.Concatenate(name=\"concat1\")([conv1, up1])\n",
    "conv11 = Conv2dBatchLayer(32, 3, name_=\"conv11\")(concat1)\n",
    "\n",
    "last_conv = layers.Conv2D(1, 3, strides=1, padding='same', kernel_initializer=initializer, name=\"last_conv\")(conv11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Sequential)              (None, 128, 128, 32) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 32)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Sequential)              (None, 64, 64, 64)   18752       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Sequential)              (None, 32, 32, 128)  74368       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 128)  0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Sequential)              (None, 16, 16, 256)  296192      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 256)    0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Sequential)              (None, 8, 8, 512)    1182208     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 512)    0           conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Sequential)              (None, 4, 4, 1024)   4723712     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up5 (Conv2DTranspose)           (None, 8, 8, 512)    4719104     conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concat5 (Concatenate)           (None, 8, 8, 1024)   0           conv5[0][0]                      \n",
      "                                                                 up5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Sequential)              (None, 8, 8, 512)    4721152     concat5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up4 (Conv2DTranspose)           (None, 16, 16, 256)  1179904     conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concat4 (Concatenate)           (None, 16, 16, 512)  0           conv4[0][0]                      \n",
      "                                                                 up4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv8 (Sequential)              (None, 16, 16, 256)  1180928     concat4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up3 (Conv2DTranspose)           (None, 32, 32, 128)  295040      conv8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concat3 (Concatenate)           (None, 32, 32, 256)  0           conv3[0][0]                      \n",
      "                                                                 up3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv9 (Sequential)              (None, 32, 32, 128)  295552      concat3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up2 (Conv2DTranspose)           (None, 64, 64, 64)   73792       conv9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concat2 (Concatenate)           (None, 64, 64, 128)  0           conv2[0][0]                      \n",
      "                                                                 up2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Sequential)             (None, 64, 64, 64)   74048       concat2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up1 (Conv2DTranspose)           (None, 128, 128, 32) 18464       conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16384)        0           conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concat1 (Concatenate)           (None, 128, 128, 64) 0           conv1[0][0]                      \n",
      "                                                                 up1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          3277000     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv11 (Sequential)             (None, 128, 128, 32) 18592       concat1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 200)          40200       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 200)          40200       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "last_conv (Conv2D)              (None, 128, 128, 1)  289         conv11[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 22,229,945\n",
      "Trainable params: 22,223,929\n",
      "Non-trainable params: 6,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(encoder_inputs, [z_mean, z_log_var, last_conv], name=\"VAE\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (371026, 128, 128, 1) samples\n"
     ]
    }
   ],
   "source": [
    "train_x = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_train.npy\", mmap_mode='c') \n",
    "train_y = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_train.npy\", mmap_mode='c') \n",
    "\n",
    "qtd_traning = train_x.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (92800, 128, 128, 1) samples\n"
     ]
    }
   ],
   "source": [
    "valid_x_1 = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_val.npy\", mmap_mode='c') \n",
    "valid_y_1 = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_val.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = valid_x_1.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Normalization and Batches split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.          -0.         127.97928619 127.98652649]\n",
      "train_batches: 6397 valid_batches: 1600\n"
     ]
    }
   ],
   "source": [
    "value = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/scale_and_shift.npy\", mmap_mode='c') \n",
    "print(value)\n",
    "SHIFT_VALUE_X, SHIFT_VALUE_Y, SCALE_VALUE_X, SCALE_VALUE_Y = value[0], value[1], value[2], value[3]\n",
    "# SHIFT_VALUE_X, SHIFT_VALUE_Y, SCALE_VALUE_X, SCALE_VALUE_Y = utils.get_shift_scale_maxmin(train_x, train_y, valid_x_1, valid_y_1)\n",
    "\n",
    "mini_batch_size = 58\n",
    "num_train_minibatches = math.floor(train_x.shape[0]/mini_batch_size)\n",
    "num_val_minibatches = math.floor(valid_x_1.shape[0]/mini_batch_size)\n",
    "\n",
    "print(\"train_batches:\", num_train_minibatches, \"valid_batches:\", num_val_minibatches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default tf.keras metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Loss and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#get last saved epoch index and best result in validation step\n",
    "CURRENT_EPOCH, BEST_VALIDATION = utils.get_model_last_data()\n",
    "if CURRENT_EPOCH > 0:\n",
    "    print(\"Loading last model state in epoch\", CURRENT_EPOCH)\n",
    "    model.load_weights(utils.get_exp_folder_last_epoch())\n",
    "    print(\"Best validation result was PSNR=\", BEST_VALIDATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE_loss(z_mean, z_log_var, data_y, predictions):\n",
    "    loss = loss_object(data_y, predictions)\n",
    "    kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "    kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "    total_loss = loss + kl_loss\n",
    "    return loss, kl_loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 2488/6397 [09:51<15:32,  4.19it/s]"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(patch_x, patch_y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z_mean, z_log_var, predictions = model(patch_x)\n",
    "        loss, kl_loss, total_loss = VAE_loss(z_mean, z_log_var, patch_y, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(total_loss)\n",
    "    total_loss_tracker.update_state(total_loss)\n",
    "    reconstruction_loss_tracker.update_state(loss)\n",
    "    kl_loss_tracker.update_state(kl_loss) \n",
    "    \n",
    "def valid_step(valid_x, valid_y, num_val_minibatches, mini_batch_size):\n",
    "    valid_mse = tf.keras.metrics.Mean(name='val_mse')\n",
    "    valid_custom_metrics = utils.CustomMetric()\n",
    "    for i in tqdm(range(num_val_minibatches)):\n",
    "        data_x = valid_x[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "        data_y = valid_y[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "        \n",
    "        data_x = tf.convert_to_tensor(data_x, dtype=tf.float32)\n",
    "        data_y = tf.convert_to_tensor(data_y, dtype=tf.float32)\n",
    "        \n",
    "        data_x = ((data_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "        data_y = ((data_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "        \n",
    "        z_mean, z_log_var, predictions = model(data_x)\n",
    "        loss, kl_loss, total_loss = VAE_loss(z_mean, z_log_var, data_y, predictions)\n",
    "        valid_mse(total_loss)\n",
    "\n",
    "        predictions = predictions.numpy()\n",
    "        data_y = data_y.numpy()\n",
    "        \n",
    "        #feed the metric evaluator\n",
    "        valid_custom_metrics.feed(data_y, predictions)\n",
    "\n",
    "    #get metric results\n",
    "    psnr, nrmse = valid_custom_metrics.result()\n",
    "    valid_mse_result = valid_mse.result().numpy()\n",
    "    valid_custom_metrics.reset_states()\n",
    "    valid_mse.reset_states()\n",
    "    return psnr, nrmse, valid_mse_result\n",
    "    \n",
    "MAX_EPOCHS = 100\n",
    "EVAL_STEP = 1\n",
    "CONST_GAMA = 0.001\n",
    "\n",
    "\n",
    "for epoch in range(CURRENT_EPOCH, MAX_EPOCHS):\n",
    "    \n",
    "    #TRAINING\n",
    "    print(\"TRAINING EPOCH\", epoch)\n",
    "   \n",
    "    for k in tqdm(range(0, num_train_minibatches)):\n",
    "        seismic_x = train_x[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        seismic_y = train_y[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        \n",
    "        seismic_x = tf.convert_to_tensor(seismic_x, dtype=tf.float32)\n",
    "        seismic_y = tf.convert_to_tensor(seismic_y, dtype=tf.float32)\n",
    "        \n",
    "        seismic_x = ((seismic_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "        seismic_y = ((seismic_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "        \n",
    "        train_step(seismic_x, seismic_y)\n",
    "        \n",
    "        \n",
    "    #VALIDATION\n",
    "    if epoch%EVAL_STEP == 0:\n",
    "        clear_output()\n",
    "        \n",
    "        print(\"VALIDATION EPOCH\", epoch)\n",
    "        #saving last epoch model\n",
    "        model.save_weights(utils.get_exp_folder_last_epoch(), save_format='tf')\n",
    "       \n",
    "        #valid with set 1\n",
    "        print(\"Validation set\")\n",
    "        psnr_1, nrmse_1, mse_1 = valid_step(valid_x_1, valid_y_1, num_val_minibatches, mini_batch_size)\n",
    "        \n",
    "        #valid with set 2\n",
    "        #print(\"Validation set 2\")\n",
    "        #psnr_2, nrmse_2, mse_2 = valid_step(valid_x_2, valid_y_2, num_val_minibatches, mini_batch_size)\n",
    "        psnr_2, nrmse_2, mse_2 = 0, 0, 0\n",
    "        \n",
    "        #valid with set 3\n",
    "        #print(\"Validation set 3\")\n",
    "        #psnr_3, nrmse_3, mse_3 = valid_step(valid_x_3, valid_y_3, num_val_minibatches, mini_batch_size)\n",
    "        psnr_3, nrmse_3, mse_3 = 0, 0, 0\n",
    "        \n",
    "        utils.update_chart_data(epoch=epoch, train_mse=train_loss.result().numpy(), \n",
    "                                valid_mse=[mse_1,mse_2,mse_3], psnr=[psnr_1,psnr_2,psnr_3], nrmse=[nrmse_1,nrmse_2, nrmse_3])\n",
    "#         utils.draw_chart()\n",
    "        \n",
    "        #saving best validation model\n",
    "        if psnr_1 > BEST_VALIDATION:\n",
    "            BEST_VALIDATION = psnr_1\n",
    "            model.save_weights(utils.get_exp_folder_best_valid(), save_format='tf')\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    total_loss_tracker.reset_states()\n",
    "    reconstruction_loss_tracker.reset_states()\n",
    "    kl_loss_tracker.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.draw_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimentos results\n",
    "print(utils.get_experiment_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "model.load_weights(utils.get_exp_folder_best_valid())\n",
    "CONST_GAMA = 0.001\n",
    "\n",
    "# valid_x_1 = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_val.npy\", mmap_mode='c') \n",
    "# valid_y_1 = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_val.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = valid_x_1.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n",
    "\n",
    "# #normalization\n",
    "# test_x = utils.shift_and_normalize(test_x, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "# test_y = utils.shift_and_normalize(test_y, SHIFT_VALUE_Y, SCALE_VALUE_Y) \n",
    "\n",
    "#batches\n",
    "num_val_minibatches = math.floor(valid_x_1.shape[0]/mini_batch_size)\n",
    "# test_batches = utils.random_mini_batches(test_x, test_y, None, None, 8, seed=0)\n",
    "\n",
    "#metrics\n",
    "val_mse = tf.keras.metrics.MeanSquaredError(name='val_mse')\n",
    "val_custom_metrics = utils.CustomMetric()\n",
    "\n",
    "f = open('/home/arthursrr/Documentos/Audio_Inpainting/Datasets/idx_genders_val.json', \"r\") \n",
    "idx_gen = json.loads(f.read()) \n",
    "\n",
    "for k in idx_gen:\n",
    "    for i in tqdm(idx_gen[k]):\n",
    "        data_x = valid_x_1[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "        data_y = valid_y_1[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "\n",
    "        data_x = tf.convert_to_tensor(data_x, dtype=tf.float32)\n",
    "        data_y = tf.convert_to_tensor(data_y, dtype=tf.float32)\n",
    "\n",
    "        data_x = ((data_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "        data_y = ((data_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "\n",
    "        predictions = model(data_x)\n",
    "        test_mse(data_y, predictions)\n",
    "\n",
    "        predictions = predictions.numpy()\n",
    "        data_y = data_y.numpy()\n",
    "\n",
    "        #feed the metric evaluator\n",
    "        val_custom_metrics.feed(data_y, predictions)\n",
    "\n",
    "    #get metric results\n",
    "    psnr, nrmse = val_custom_metrics.result()\n",
    "    val_mse_result = test_mse.result().numpy()\n",
    "    val_custom_metrics.reset_states()\n",
    "    val_mse.reset_states()\n",
    "    \n",
    "    print(k ,\"\\nPSNR:\", psnr,\"\\nNRMSE:\", nrmse)\n",
    "\n",
    "# Closing file \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "model.load_weights(utils.get_exp_folder_best_valid())\n",
    "CONST_GAMA = 0.001\n",
    "test_x = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_test.npy\", mmap_mode='c') \n",
    "test_y = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_test.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = test_x.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n",
    "\n",
    "# #normalization\n",
    "# test_x = utils.shift_and_normalize(test_x, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "# test_y = utils.shift_and_normalize(test_y, SHIFT_VALUE_Y, SCALE_VALUE_Y) \n",
    "\n",
    "#batches\n",
    "num_test_minibatches = math.floor(test_x.shape[0]/mini_batch_size)\n",
    "# test_batches = utils.random_mini_batches(test_x, test_y, None, None, 8, seed=0)\n",
    "\n",
    "#metrics\n",
    "test_mse = tf.keras.metrics.MeanSquaredError(name='train_mse')\n",
    "test_custom_metrics = utils.CustomMetric()\n",
    "\n",
    "f = open('/home/arthursrr/Documentos/Audio_Inpainting/Datasets/idx_genders_test.json', \"r\") \n",
    "idx_gen = json.loads(f.read()) \n",
    "\n",
    "for k in idx_gen:\n",
    "    for i in tqdm(idx_gen[k]):\n",
    "        data_x = test_x[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "        data_y = test_y[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "\n",
    "        data_x = tf.convert_to_tensor(data_x, dtype=tf.float32)\n",
    "        data_y = tf.convert_to_tensor(data_y, dtype=tf.float32)\n",
    "\n",
    "        data_x = ((data_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "        data_y = ((data_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "\n",
    "        predictions = model(data_x)\n",
    "        test_mse(data_y, predictions)\n",
    "\n",
    "        predictions = predictions.numpy()\n",
    "        data_y = data_y.numpy()\n",
    "\n",
    "        #feed the metric evaluator\n",
    "        test_custom_metrics.feed(data_y, predictions)\n",
    "\n",
    "    #get metric results\n",
    "    psnr, nrmse = test_custom_metrics.result()\n",
    "    test_mse_result = test_mse.result().numpy()\n",
    "    test_custom_metrics.reset_states()\n",
    "    test_mse.reset_states()\n",
    "    \n",
    "    print(k ,\"\\nPSNR:\", psnr,\"\\nNRMSE:\", nrmse)\n",
    "\n",
    "# Closing file \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load best model\n",
    "model.load_weights(utils.get_exp_folder_best_valid())\n",
    "CONST_GAMA = 0.001\n",
    "test_x = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_test.npy\", mmap_mode='c') \n",
    "test_y = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_test.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = test_x.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n",
    "\n",
    "# #normalization\n",
    "# test_x = utils.shift_and_normalize(test_x, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "# test_y = utils.shift_and_normalize(test_y, SHIFT_VALUE_Y, SCALE_VALUE_Y) \n",
    "\n",
    "#batches\n",
    "num_test_minibatches = math.floor(test_x.shape[0]/mini_batch_size)\n",
    "# test_batches = utils.random_mini_batches(test_x, test_y, None, None, 8, seed=0)\n",
    "\n",
    "#metrics\n",
    "test_mse = tf.keras.metrics.MeanSquaredError(name='test_mse')\n",
    "test_custom_metrics = utils.CustomMetric()\n",
    "\n",
    "f = open('/home/arthursrr/Documentos/Audio_Inpainting/Datasets/idx_genders_test.json', \"r\") \n",
    "idx_gen = json.loads(f.read()) \n",
    "\n",
    "for k in idx_gen:\n",
    "    if k == \"Experimental\" or k == \"Hip-Hop\" or k == \"Jazz\":\n",
    "        for i in tqdm(idx_gen[k]):\n",
    "            data_x = test_x[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "            data_y = test_y[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "\n",
    "            data_x = tf.convert_to_tensor(data_x, dtype=tf.float32)\n",
    "            data_y = tf.convert_to_tensor(data_y, dtype=tf.float32)\n",
    "\n",
    "            data_x = ((data_x+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "            data_y = ((data_y+SHIFT_VALUE_Y)/SCALE_VALUE_Y)+CONST_GAMA\n",
    "\n",
    "            data_x = data_x.numpy()\n",
    "            data_y = data_y.numpy()\n",
    "\n",
    "            #feed the metric evaluator\n",
    "            test_custom_metrics.feed(data_y, data_x)\n",
    "\n",
    "        #get metric results\n",
    "        psnr, nrmse = test_custom_metrics.result()\n",
    "        test_mse_result = test_mse.result().numpy()\n",
    "        test_custom_metrics.reset_states()\n",
    "        test_mse.reset_states()\n",
    "    \n",
    "        print(k ,\"\\nPSNR:\", psnr,\"\\nNRMSE:\", nrmse)\n",
    "\n",
    "# Closing file \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def griffin_lim(S, frame_length=256, fft_length=255, stride=64):\n",
    "    '''\n",
    "    TensorFlow implementation of Griffin-Lim\n",
    "    Based on https://github.com/Kyubyong/tensorflow-exercises/blob/master/Audio_Processing.ipynb\n",
    "    '''\n",
    "    S = tf.expand_dims(S, 0)\n",
    "    S_complex = tf.identity(tf.cast(S, dtype=tf.complex64))\n",
    "    y = tf.signal.inverse_stft(S_complex, frame_length, stride, fft_length=fft_length)\n",
    "    for i in range(100):\n",
    "        est = tf.signal.stft(y, frame_length, stride, fft_length=fft_length)\n",
    "        angles = est / tf.cast(tf.maximum(1e-16, tf.abs(est)), tf.complex64)\n",
    "        y = tf.signal.inverse_stft(S_complex * angles, frame_length, stride, fft_length=fft_length)\n",
    "    return tf.squeeze(y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(utils.get_exp_folder_best_valid())\n",
    "\n",
    "test_x = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/X_test.npy\", mmap_mode='c') \n",
    "test_y = np.load(\"/mnt/backup/arthur/Free_Music_Archive/Spectrogramas/y_test.npy\", mmap_mode='c')\n",
    "\n",
    "qtd_traning = test_x.shape\n",
    "print(\"Loaded\",qtd_traning, \"samples\")\n",
    "\n",
    "#batches\n",
    "num_test_minibatches = math.floor(test_x.shape[0]/mini_batch_size)\n",
    "\n",
    "#metrics\n",
    "test_mse = tf.keras.metrics.MeanSquaredError(name='test_mse')\n",
    "test_custom_metrics = utils.CustomMetric()\n",
    "\n",
    "CONST_GAMA = 0.001\n",
    "\n",
    "f = open('/home/arthursrr/Documentos/Audio_Inpainting/Datasets/idx_genders_test.json', \"r\") \n",
    "idx_gen = json.loads(f.read()) \n",
    "\n",
    "wave_original = None\n",
    "wave_corte = None\n",
    "wave_pred = None\n",
    "\n",
    "for k in idx_gen:\n",
    "    path_gen = \"/mnt/backup/arthur/Free_Music_Archive/Teste/\"+k\n",
    "    if not os.path.exists(path_gen):\n",
    "            os.makedirs(path_gen)\n",
    "            os.makedirs(path_gen+\"/original\")\n",
    "            os.makedirs(path_gen+\"/cortado\")\n",
    "            os.makedirs(path_gen+\"/predito\")\n",
    "    for i in tqdm(idx_gen[k]):\n",
    "        data_x = test_x[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "        data_y = test_y[i * mini_batch_size : i * mini_batch_size + mini_batch_size]\n",
    "\n",
    "        data_norm = ((tf.convert_to_tensor(data_x, dtype=tf.float32)+SHIFT_VALUE_X)/SCALE_VALUE_X)+CONST_GAMA\n",
    "\n",
    "        predictions = model(data_norm)\n",
    "        \n",
    "        predictions = (((predictions-CONST_GAMA)*SCALE_VALUE_X)-SHIFT_VALUE_X).numpy()\n",
    "        \n",
    "        #predictions = utils.inv_shift_and_normalize(predictions, SHIFT_VALUE_Y, SCALE_VALUE_Y)   \n",
    "        \n",
    "        audio_original = None\n",
    "        audio_corte = None\n",
    "        audio_pred = None\n",
    "        \n",
    "        for j in range(mini_batch_size):\n",
    "            if j==0:\n",
    "                audio_original = data_y[j,:,:,0]\n",
    "                audio_corte = data_x[j,:,:,0]\n",
    "                audio_pred = predictions[j,:,:,0]\n",
    "            else:\n",
    "                audio_original = np.concatenate((audio_original, data_y[j,:,:,0]), axis=0)\n",
    "                audio_corte = np.concatenate((audio_corte, data_x[j,:,:,0]), axis=0)\n",
    "                audio_pred = np.concatenate((audio_pred, predictions[j,:,:,0]), axis=0)\n",
    "        \n",
    "        wave_original = griffin_lim(audio_original, frame_length=256, fft_length=255, stride=64)\n",
    "        wave_corte = griffin_lim(audio_corte, frame_length=256, fft_length=255, stride=64)\n",
    "        wave_pred = griffin_lim(audio_pred, frame_length=256, fft_length=255, stride=64)\n",
    "        \n",
    "        sf.write(path_gen+\"/original/\"+str(i)+\".wav\", wave_original, 16000, subtype='PCM_16')\n",
    "        sf.write(path_gen+\"/cortado/\"+str(i)+\".wav\", wave_corte, 16000, subtype='PCM_16')\n",
    "        sf.write(path_gen+\"/predito/\"+str(i)+\".wav\", wave_pred, 16000, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pred = None\n",
    "for i in range(0, 58):\n",
    "    if i==0:\n",
    "        audio_pred = predictions[i,:,:,0]\n",
    "    else:\n",
    "        audio_pred = np.concatenate((audio_pred, predictions[i,:,:,0]), axis=0)\n",
    "audio_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_corte = None\n",
    "for i in range(0, 58):\n",
    "    if i==0:\n",
    "        audio_corte = data_x[i,:,:,0]\n",
    "    else:\n",
    "        audio_corte = np.concatenate((audio_corte, data_x[i,:,:,0]), axis=0)\n",
    "audio_corte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_original = None\n",
    "for i in range(0, 58):\n",
    "    if i==0:\n",
    "        audio_original = data_y[i,:,:,0]\n",
    "    else:\n",
    "        audio_original = np.concatenate((audio_original, data_y[i,:,:,0]), axis=0)\n",
    "audio_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_original = griffin_lim(audio_original, frame_length=256, fft_length=255, stride=64)\n",
    "ipd.Audio(wave_original, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_corte = griffin_lim(audio_corte, frame_length=256, fft_length=255, stride=64)\n",
    "ipd.Audio(wave_corte, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_pred = griffin_lim(audio_pred, frame_length=256, fft_length=255, stride=64)\n",
    "ipd.Audio(wave_pred, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import soundfile as sf\n",
    "# sf.write('x.wav', wave_corte, 16000, subtype='PCM_16')\n",
    "# sf.write('pred.wav', wave_pred, 16000, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
